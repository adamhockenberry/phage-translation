{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO, Entrez\n",
    "Entrez.email = 'adam.hockenberry@utexas.edu'\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First read and place a few restrictions on the full data table\n",
    "\n",
    "The relevant information was downloaded from: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&Completeness_s=complete&VirusLineage_ss=Bacteriophage,%20all%20taxids&Proviral_s=include in November, 2020. Which is just: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&Proviral_s=include where I selected \"Bacteriophage, all taxids (53348)\" from the \"Virus\" search box and \"complete\" from the \"Nucleotide Completeness\" section. \n",
    "\n",
    "Raw data consists of a `.csv` containing relevant information about each sequence, a large `.fasta` file containing (nucleotide) genome sequences, and a large `.fasta` file containing coding sequences for each genome. I re-located and renamed these files in the `../Data/NCBI_phage_db/` directory:\n",
    "\n",
    "1. `all_complete_phage_info_11_2020.csv`\n",
    "2. `all_complete_phage_NTs_11_2020.fasta`\n",
    "3. `all_complete_phage_CDSs_11_2020.fasta`\n",
    "\n",
    "All of the resulting code assumes that these are valid file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, read in the info file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/NCBI_phage_db/all_complete_phage_info_11_2020.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use this space for some basic data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limit the dataset to only consider phages with explicitly defined hosts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Host'].isnull()==False]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve host taxonomy by querying strings to NCBI\n",
    "\n",
    "This code takes some time and space, and is a bit finicky since we're basically trying to convert the messy string in the `Host` field to a meaningful string/number based on the NCBI taxonomy standards.\n",
    "\n",
    "I'm surprised that this isn't done from the start, but such is the messiness of public databases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define the taxonomy levels that I care about\n",
    "taxonomies_to_fetch = ['superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "\n",
    "problematic_hosts = []\n",
    "###Iterate through the *set* of host strings\n",
    "for host in list(set(df['Host']))[:]:\n",
    "    #Identify the indices that match this host string (to be used later)\n",
    "    matching_indices = df[df['Host']==host].index\n",
    "    print(host)\n",
    "    #Try searching for the string\n",
    "    handle = Entrez.esearch(db='Taxonomy', term=host)\n",
    "    record = Entrez.read(handle)\n",
    "    #Append anything with even a slight problem to an error bucket\n",
    "    if len(record['IdList']) != 1:\n",
    "        problematic_hosts.append(host)\n",
    "        continue\n",
    "        \n",
    "    #Actually retreive the full taxonomy results\n",
    "    record_id = record['IdList'][0]\n",
    "    handle = Entrez.efetch(db=\"Taxonomy\", id=record_id, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    #Make sure no errors popped up again\n",
    "    if len(records) != 1:\n",
    "        problematic_hosts.append(host)\n",
    "        continue        \n",
    "    record = records[0]\n",
    "    ###First get the genetic code right\n",
    "    df.at[matching_indices, 'GeneticCode'] = record['GeneticCode']['GCId']\n",
    "    ###Now possibly add the record itself\n",
    "    if record['Rank'] in taxonomies_to_fetch:\n",
    "        df.at[matching_indices, 'Host_{}_id'.format(record['Rank'])] = record['TaxId']\n",
    "        df.at[matching_indices, 'Host_{}_name'.format(record['Rank'])] = record['ScientificName']\n",
    "    ###Finally go through the lineage\n",
    "    lineage = record['LineageEx']\n",
    "    for i in lineage:\n",
    "        if i['Rank'] in taxonomies_to_fetch:\n",
    "            df.at[matching_indices, 'Host_{}_id'.format(i['Rank'])] = i['TaxId']\n",
    "            df.at[matching_indices, 'Host_{}_name'.format(i['Rank'])] = i['ScientificName']\n",
    "    time.sleep(6) ###Should probably sleep for some period of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check out some basic summary stats from the resulting addtions to `df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host_species_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GeneticCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now clean up / fix some of the problematic cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_hosts = list(set(problematic_hosts))\n",
    "print(len(problematic_hosts))\n",
    "for annoyance in problematic_hosts:\n",
    "    print(annoyance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix the cases with special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_problematic = []\n",
    "for host in problematic_hosts:\n",
    "    matching_indices = df[df['Host']==host].index\n",
    "    host = host.replace(':', ' ')\n",
    "    host = host.replace('[', '').replace(']', '')\n",
    "    host = host.replace('(', ' ').replace(')', ' ')\n",
    "    print(host)\n",
    "    handle = Entrez.esearch(db='Taxonomy', term=host)\n",
    "    record = Entrez.read(handle)\n",
    "    if len(record['IdList']) != 1:\n",
    "        still_problematic.append(host)\n",
    "        continue\n",
    "    record_id = record['IdList'][0]\n",
    "    handle = Entrez.efetch(db=\"Taxonomy\", id=record_id, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    if len(records) != 1:\n",
    "        still_problematic.append(host)\n",
    "        continue        \n",
    "    record = records[0]\n",
    "    ###First get the genetic code right\n",
    "    df.at[matching_indices, 'GeneticCode'] = record['GeneticCode']['GCId']\n",
    "    ###Now possibly add the record itself\n",
    "    if record ['Rank'] in taxonomies_to_fetch:\n",
    "        df.at[matching_indices, 'Host_{}_id'.format(record['Rank'])] = record['TaxId']\n",
    "        df.at[matching_indices, 'Host_{}_name'.format(record['Rank'])] = record['ScientificName']\n",
    "    ###Finally go through the lineage\n",
    "    lineage = record['LineageEx']\n",
    "    for i in lineage:\n",
    "        if i['Rank'] in taxonomies_to_fetch:\n",
    "            df.at[matching_indices, 'Host_{}_id'.format(i['Rank'])] = i['TaxId']\n",
    "            df.at[matching_indices, 'Host_{}_name'.format(i['Rank'])] = i['ScientificName']\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(still_problematic)))\n",
    "still_problematic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cases with annoying genuses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_problematic = []\n",
    "for host in still_problematic:\n",
    "    matching_indices = df[df['Host']==host].index\n",
    "    host = host.replace(':', ' ')\n",
    "    host = host.replace('[', '').replace(']', '')\n",
    "    host = host.replace('(', ' ').replace(')', ' ')\n",
    "    print(host)\n",
    "    handle = Entrez.esearch(db='Taxonomy', term=host)\n",
    "    record = Entrez.read(handle)\n",
    "    if len(record['IdList']) == 0:\n",
    "        really_problematic.append(host)\n",
    "        continue\n",
    "    temp_ids = record['IdList']\n",
    "    successful_ids = []\n",
    "    for record_id in temp_ids:\n",
    "        handle = Entrez.efetch(db=\"Taxonomy\", id=record_id, retmode=\"xml\")\n",
    "        records = Entrez.read(handle)\n",
    "        if len(records) != 1:\n",
    "            really_problematic.append(host)\n",
    "            continue        \n",
    "        record = records[0]\n",
    "        lineage = record['LineageEx']\n",
    "        for i in lineage:\n",
    "            if i['Rank']=='superkingdom' and i['ScientificName'] =='Bacteria':\n",
    "                successful_ids.append(record_id)\n",
    "    if len(successful_ids) == 1:\n",
    "        record_id = successful_ids[0]\n",
    "    else:\n",
    "        really_problematic.append(host)\n",
    "    \n",
    "    handle = Entrez.efetch(db=\"Taxonomy\", id=record_id, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    if len(records) != 1:\n",
    "        really_problematic.append(host)\n",
    "        continue        \n",
    "    record = records[0]\n",
    "    ###First get the genetic code right\n",
    "    df.at[matching_indices, 'GeneticCode'] = record['GeneticCode']['GCId']\n",
    "    ###Now possibly add the record itself\n",
    "    if record ['Rank'] in taxonomies_to_fetch:\n",
    "        df.at[matching_indices, 'Host_{}_id'.format(record['Rank'])] = record['TaxId']\n",
    "        df.at[matching_indices, 'Host_{}_name'.format(record['Rank'])] = record['ScientificName']\n",
    "    ###Finally go through the lineage\n",
    "    lineage = record['LineageEx']\n",
    "    for i in lineage:\n",
    "        if i['Rank'] in taxonomies_to_fetch:\n",
    "            df.at[matching_indices, 'Host_{}_id'.format(i['Rank'])] = i['TaxId']\n",
    "            df.at[matching_indices, 'Host_{}_name'.format(i['Rank'])] = i['ScientificName']\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(really_problematic))\n",
    "print(really_problematic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally some manual inspection lead to this kludge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [1199, 1531298, 1353243, 2030816, 29523, 551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomies_to_fetch = ['superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "problematic_hosts = []\n",
    "for host, answer in zip(really_problematic, answers):\n",
    "    matching_indices = df[df['Host']==host].index\n",
    "    if df.loc[matching_indices]['Host_superkingdom_id'].isnull().all()==False:\n",
    "        print('Skipping')\n",
    "        continue\n",
    "    print(host)\n",
    "    record_id = str(answer)\n",
    "    handle = Entrez.efetch(db=\"Taxonomy\", id=record_id, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)    \n",
    "    record = records[0]\n",
    "    ###First get the genetic code right\n",
    "    df.at[matching_indices, 'GeneticCode'] = record['GeneticCode']['GCId']\n",
    "    ###Now possibly add the record itself\n",
    "    if record ['Rank'] in taxonomies_to_fetch:\n",
    "        df.at[matching_indices, 'Host_{}_id'.format(record['Rank'])] = record['TaxId']\n",
    "        df.at[matching_indices, 'Host_{}_name'.format(record['Rank'])] = record['ScientificName']\n",
    "    ###Finally go through the lineage\n",
    "    lineage = record['LineageEx']\n",
    "    for i in lineage:\n",
    "        if i['Rank'] in taxonomies_to_fetch:\n",
    "            df.at[matching_indices, 'Host_{}_id'.format(i['Rank'])] = i['TaxId']\n",
    "            df.at[matching_indices, 'Host_{}_name'.format(i['Rank'])] = i['ScientificName']\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the new and improved file!**\n",
    "\n",
    "Ideally, the above code should never need to be run again but for the purposes of someone trying to replicate this code on newer verions of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host_superkingdom_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../Data/NCBI_phage_db/all_complete_phage_info_HOSTTAXONOMY_11_2020.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further processing of the large `df` that includes taxonomy info\n",
    "\n",
    "Re-read the `df` from the file I just wrote and select the rows that I care about for a more useful working `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/NCBI_phage_db/all_complete_phage_info_HOSTTAXONOMY_11_2020.tsv', sep='\\t')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Who are these eukaryotes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Host_superkingdom_name']!='Bacteria'][['Host','Host_species_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get rid of 'em**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Host_superkingdom_name']=='Bacteria']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Who avoided proper classification?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Host_genus_id'].isnull()==True][['Host', 'Host_genus_name']]\n",
    "# df[df['Host_species_id'].isnull()==True][['Host', 'Host_species_name']]\n",
    "df[df['Host_species_id'].isnull()==True]['Host'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get rid of 'em**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Host_species_id'].isnull()==False]\n",
    "print(df.shape)\n",
    "df['Host_species_id'] = df['Host_species_id'].astype(int)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weird genetic codes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GeneticCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get rid of 'em**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['GeneticCode']==11]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write to file!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../Data/NCBI_phage_db/paper_dataset_11_2020.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the top host species and separate the genomes into individual directories\n",
    "\n",
    "This will create a lot of different files! It will make directories for each of the `top_species` and populate these directories with all matching phage genomes in `.fasta` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df['Host_species_id'].value_counts()\n",
    "top_species = list(vc[vc >= 50].index)\n",
    "print(len(top_species))\n",
    "print(top_species[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_dir = '../../Data/NCBI_phage_db/all_complete_phage_NTs_11_2020.fasta'\n",
    "for host_taxid in top_species:\n",
    "    save_dir = '../../Data/NCBI_phage_db/phage_genomes/{}_phage_genomes/'.format(host_taxid)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    temp_df = df[df['Host_species_id']==host_taxid]\n",
    "    print(temp_df.shape)\n",
    "    assert len(set(list(temp_df['Accession']))) == len(list(temp_df['Accession']))\n",
    "    selected_accession_numbers = list(temp_df['Accession'])\n",
    "    all_genomes = SeqIO.parse(nts_dir, 'fasta')\n",
    "    found = 0\n",
    "    for genome in all_genomes:\n",
    "        simple_id = genome.id.split('.')[0]\n",
    "        if simple_id in selected_accession_numbers:\n",
    "            with open(save_dir+'{}.fasta'.format(simple_id), 'w') as outfile:\n",
    "                SeqIO.write(genome, outfile, 'fasta')\n",
    "                found += 1\n",
    "    print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host_species_name'].value_counts().head(n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**et voila**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
