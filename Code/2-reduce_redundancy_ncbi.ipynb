{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial notes\n",
    "\n",
    "This code assumes that you have ran through the previous notebook `1-parse_NCBI_database.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline portion\n",
    "\n",
    "I manually ran fastANI on the set of phage genomes (`.fasta` files) for each host.\n",
    "\n",
    "For example:\n",
    "```\n",
    "find ./phage_genomes/562_phage_genomes/*.fasta -type f> file_listing.txt\n",
    "\n",
    "fastANI --ql file_listing.txt --rl file_listing.txt --threads 10 --fragLen 300 --minFraction 0.8 -o 562_ANI.output\n",
    "```\n",
    "\n",
    "To run for all hosts, just replace both instances of `562` in the above code. Didn't seem worth writing a bash script so I manually ran this on a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cluster information to the existing database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('../Data/NCBI_phage_db/paper_dataset_11_2020.tsv', sep='\\t')\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = full_df['Host_species_id'].value_counts()\n",
    "taxonomy_list = list(vc[vc >= 50].index)\n",
    "print(len(taxonomy_list))\n",
    "print(taxonomy_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_id = '562'\n",
    "input_df = pd.read_csv('../Data/NCBI_phage_db/fastANI_results/{}_ANI.output'.format(taxon_id), sep='\\t', header=None)\n",
    "print('Shape:', input_df.shape)\n",
    "print('Non-null shape:', input_df[input_df[2].isnull()==False].shape)\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['temp'] = input_df[0].str.split(\"/\").str[-1]\n",
    "input_df['query_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df['temp'] = input_df[1].str.split(\"/\").str[-1]\n",
    "input_df['ref_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df = input_df[['query_seq', 'ref_seq', 2, 3, 4]]\n",
    "print(input_df[input_df[2]==100.].shape)\n",
    "input_df = input_df[input_df['query_seq'] != input_df['ref_seq']]\n",
    "print(input_df.shape)\n",
    "input_df.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-create the cd-hit-est algorithm for clustering and write clusters to a  file\n",
    "\n",
    "There's probably a faster way to do this but it seemed straightforward enough to quickly write up the greedy incremental clustering approach. For each genome, I'm writing entries for two new columns: `arbitrary_cluster_id` and `ranking_in_cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set sequence identity threshold\n",
    "thresh = 95\n",
    "\n",
    "for taxon_id in taxonomy_list[:]:\n",
    "    print(taxon_id)\n",
    "    ###Read in the ANI output\n",
    "    input_df = pd.read_csv('../Data/Other_possible_dbs/NCBI_phage_db/fastANI_results/{}_ANI.output'.format(taxon_id), sep='\\t', header=None)\n",
    "    ###Processing some columns\n",
    "    input_df['temp'] = input_df[0].str.split(\"/\").str[-1]\n",
    "    input_df['query_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "    input_df['temp'] = input_df[1].str.split(\"/\").str[-1]\n",
    "    input_df['ref_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "    input_df = input_df[['query_seq', 'ref_seq', 2, 3, 4]]\n",
    "    #Remove self vs self comparisons\n",
    "    input_df = input_df[input_df['query_seq'] != input_df['ref_seq']]\n",
    "    \n",
    "    ###Make a copy of the input\n",
    "    input_df_copy = input_df.copy(deep=True)\n",
    "    ###Select the species I care about from the full dataframe\n",
    "    species_df = full_df[full_df['Host_species_id']==taxon_id].sort_values('Length', ascending=False)\n",
    "    #Establish buckets\n",
    "    clusters = []\n",
    "    found = []\n",
    "    for index in species_df.index:\n",
    "        temp_accession = species_df.loc[index]['Accession']\n",
    "        ### Records should be sorted in order! (see above)\n",
    "        if temp_accession in found:\n",
    "            continue\n",
    "        ###Find all instances of this record in the ANI dataframe\n",
    "        temp_df = input_df_copy[(input_df_copy['query_seq']==temp_accession) | (input_df_copy['ref_seq']==temp_accession)]\n",
    "        ###Select all cases where the identity is greater than the specified threshold\n",
    "        temp_df = temp_df[temp_df[2] > thresh]\n",
    "        ###Add all these hits and call them a cluster!\n",
    "        temp_cluster = list(set(list(temp_df['query_seq'])+list(temp_df['ref_seq'])))\n",
    "        ###Now try to expand that cluster\n",
    "        stop = False\n",
    "        while stop == False:\n",
    "            starting = len(temp_cluster)\n",
    "            temp_df = input_df_copy[(input_df_copy['query_seq'].isin(temp_cluster)) | \n",
    "                                        (input_df_copy['ref_seq'].isin(temp_cluster))]\n",
    "            temp_df = temp_df[temp_df[2] > thresh]\n",
    "            temp_cluster = list(set(list(temp_df['query_seq'])+list(temp_df['ref_seq'])))\n",
    "            ###Break if I did not add anyone this iteration\n",
    "            if len(temp_cluster) == starting:\n",
    "                stop = True\n",
    "                \n",
    "        if len(temp_cluster) == 0:\n",
    "            temp_cluster = [temp_accession]\n",
    "            \n",
    "        clusters.append(temp_cluster)\n",
    "        found.extend(temp_cluster)\n",
    "        input_df_copy = input_df_copy[input_df_copy['query_seq'].isin(temp_cluster) == False]\n",
    "        input_df_copy = input_df_copy[input_df_copy['ref_seq'].isin(temp_cluster) == False]\n",
    "    print(len(clusters), len(found))\n",
    "    \n",
    "    ###Add to the dataframe\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        temp_df = species_df[species_df['Accession'].isin(cluster)]\n",
    "        ###Sorting is done to percolate RefSeq entries to the top, followed by long genomes\n",
    "        temp_df = temp_df.sort_values(['Sequence_Type', 'Length'], ascending=[False, False])\n",
    "        for j, index in enumerate(temp_df.index):\n",
    "            full_df.at[index, 'arbitrary_cluster_id'] = i + 1\n",
    "            full_df.at[index, 'ranking_in_cluster'] = j + 1\n",
    "\n",
    "    with open('../Data/Other_possible_dbs/NCBI_phage_db/fastANI_results/{}_clusters.json'.format(taxon_id), 'w') as outfile:\n",
    "        json.dump(clusters, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['arbitrary_cluster_id'] = full_df['arbitrary_cluster_id'].astype(pd.Int64Dtype())\n",
    "full_df['ranking_in_cluster'] = full_df['ranking_in_cluster'].astype(pd.Int64Dtype())\n",
    "\n",
    "full_df = full_df[full_df['Host_species_id'].isin(taxonomy_list)]\n",
    "\n",
    "full_df.to_csv('../Data/Other_possible_dbs/NCBI_phage_db/'\n",
    "               'paper_dataset_11_2020_with_clusters.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch from here on out..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_id = 562\n",
    "input_df = pd.read_csv('../Data/NCBI_phage_db/fastANI_results/{}_ANI.output'.format(taxon_id), sep='\\t', header=None)\n",
    "print('Shape:', input_df.shape)\n",
    "print('Non-null shape:', input_df[input_df[2].isnull()==False].shape)\n",
    "input_df['temp'] = input_df[0].str.split(\"/\").str[-1]\n",
    "input_df['query_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df['temp'] = input_df[1].str.split(\"/\").str[-1]\n",
    "input_df['ref_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df = input_df[['query_seq', 'ref_seq', 2, 3, 4]]\n",
    "print(input_df.shape)\n",
    "\n",
    "sim_df = input_df.pivot(index='query_seq', columns='ref_seq', values=2)\n",
    "sim_matrix = sim_df.values\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/NCBI_phage_db/fastANI_results/562_clusters.json', 'r') as infile:\n",
    "    clusters = json.load(infile)\n",
    "temp = [str(item) for sublist in clusters for item in sublist if item in sim_df.index]\n",
    "ordered_sim_matrix = sim_df.loc[temp][temp].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sim_df.index), len(sim_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(nrows=1, ncols=2, figsize=(16,8))\n",
    "ax_arr[0].matshow(sim_matrix)\n",
    "ax_arr[0].set_title('Unsorted in any seemingly logical way')\n",
    "ax_arr[1].matshow(ordered_sim_matrix)\n",
    "ax_arr[1].set_title('After greedy algorithm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[2].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with stricter sequence identity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('../Data/NCBI_phage_db/paper_dataset_11_2020.tsv', sep='\\t')\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set sequence identity threshold\n",
    "thresh = 80\n",
    "taxon_id = 562\n",
    "\n",
    "###Read in the ANI output\n",
    "input_df = pd.read_csv('../Data/562_associated_data/{}_ANI_STRICT.output'.format(taxon_id), sep='\\t', header=None)\n",
    "###Processing some columns\n",
    "input_df['temp'] = input_df[0].str.split(\"/\").str[-1]\n",
    "input_df['query_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df['temp'] = input_df[1].str.split(\"/\").str[-1]\n",
    "input_df['ref_seq'] = input_df['temp'].str.split('.').str[0]\n",
    "input_df = input_df[['query_seq', 'ref_seq', 2, 3, 4]]\n",
    "#Remove self vs self comparisons\n",
    "input_df = input_df[input_df['query_seq'] != input_df['ref_seq']]\n",
    "\n",
    "###Make a copy of the input\n",
    "input_df_copy = input_df.copy(deep=True)\n",
    "###Select the species I care about from the full dataframe\n",
    "species_df = full_df[full_df['Host_species_id']==taxon_id].sort_values('Length', ascending=False)\n",
    "#Establish buckets\n",
    "clusters = []\n",
    "found = []\n",
    "for index in species_df.index:\n",
    "    temp_accession = species_df.loc[index]['Accession']\n",
    "    ### Records should be sorted in order! (see above)\n",
    "    if temp_accession in found:\n",
    "        continue\n",
    "    ###Find all instances of this record in the ANI dataframe\n",
    "    temp_df = input_df_copy[(input_df_copy['query_seq']==temp_accession) | (input_df_copy['ref_seq']==temp_accession)]\n",
    "    ###Select all cases where the identity is greater than the specified threshold\n",
    "    temp_df = temp_df[temp_df[2] > thresh]\n",
    "    ###Add all these hits and call them a cluster!\n",
    "    temp_cluster = list(set(list(temp_df['query_seq'])+list(temp_df['ref_seq'])))\n",
    "    ###Now try to expand that cluster\n",
    "    stop = False\n",
    "    while stop == False:\n",
    "        starting = len(temp_cluster)\n",
    "        temp_df = input_df_copy[(input_df_copy['query_seq'].isin(temp_cluster)) | \n",
    "                                    (input_df_copy['ref_seq'].isin(temp_cluster))]\n",
    "        temp_df = temp_df[temp_df[2] > thresh]\n",
    "        temp_cluster = list(set(list(temp_df['query_seq'])+list(temp_df['ref_seq'])))\n",
    "        ###Break if I did not add anyone this iteration\n",
    "        if len(temp_cluster) == starting:\n",
    "            stop = True\n",
    "\n",
    "    if len(temp_cluster) == 0:\n",
    "        temp_cluster = [temp_accession]\n",
    "\n",
    "    clusters.append(temp_cluster)\n",
    "    found.extend(temp_cluster)\n",
    "    input_df_copy = input_df_copy[input_df_copy['query_seq'].isin(temp_cluster) == False]\n",
    "    input_df_copy = input_df_copy[input_df_copy['ref_seq'].isin(temp_cluster) == False]\n",
    "print(len(clusters), len(found))\n",
    "\n",
    "###Add to the dataframe\n",
    "for i, cluster in enumerate(clusters):\n",
    "    temp_df = species_df[species_df['Accession'].isin(cluster)]\n",
    "    temp_df = temp_df.sort_values(['Sequence_Type', 'Length'], ascending=[False, False])\n",
    "    for j, index in enumerate(temp_df.index):\n",
    "        full_df.at[index, 'arbitrary_cluster_id'] = i + 1\n",
    "        full_df.at[index, 'ranking_in_cluster'] = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore cluster numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df['Host_species_id']==562]['ranking_in_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_df = full_df[(full_df['Host_species_id']==562)&(full_df['ranking_in_cluster']==1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestyle_df = pd.read_csv('../Data/lifestyle_results_BACPHLIP.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltogethernow = []\n",
    "for index in testy_df.index:\n",
    "    phage_id = testy_df.loc[index]['Accession']\n",
    "    if lifestyle_df[lifestyle_df['phage_id']==phage_id].shape[0] == 1:\n",
    "        alltogethernow.append(lifestyle_df[lifestyle_df['phage_id']==phage_id].iloc[0]['phage_lifestyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(alltogethernow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
