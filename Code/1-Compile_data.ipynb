{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook summary\n",
    "\n",
    "The purpose of this notebook is to create a set of `.tsv` files from various sources for both host and viral genomes. It is expected that the project organization follows the relative path where all initial files are located within `../Data`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gff3_parsing ###A separate .py library that should be available in the python path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../iCUB/')\n",
    "import iCUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_RBS_energy(df, energy_dict, col_name='RBS_energy',\\\n",
    "                   gaps=(4,10), expected_len=30, RBS_len=6):\n",
    "    '''\n",
    "    This function adds a ribosome binding site (RBS) energy column to the df based off of \n",
    "    free energy values pre-computed and stored in the corresponding energy_dict. \n",
    "    \n",
    "    Inputs:\n",
    "        df - \n",
    "        energy_dict - \n",
    "        gaps - \n",
    "        expected_len - \n",
    "    \n",
    "    Outputs:\n",
    "        df - the transformed df object now containing the energy_binding column\n",
    "        \n",
    "    '''\n",
    "    for index in df.index:\n",
    "        upstream = df.loc[index,'upstream_sequence']\n",
    "        test_string = upstream.replace('T', 'U')\n",
    "        ###Ensure that the sequence is the proper expected length\n",
    "        if len(test_string) != expected_len:\n",
    "            continue\n",
    "        ###Ensure that the sequence has no abnormal bases\n",
    "        if test_string.count('A') + test_string.count('U') +\\\n",
    "                                    test_string.count('C') + test_string.count('G') != expected_len:\n",
    "            continue\n",
    "            \n",
    "        ###Calculate the energy for the indicated gap offsets\n",
    "        energy_list = []\n",
    "        for gap in range(gaps[0],gaps[1]+1):\n",
    "             energy_list.append(energy_dict[test_string[-gap - RBS_len: -gap]])\n",
    "\n",
    "        df.at[index, col_name] = min(energy_list)        \n",
    "    return df\n",
    "\n",
    "\n",
    "def call_RNAfold(sequence):\n",
    "    sequence = sequence.replace('T', 'U')\n",
    "    MyOut = subprocess.Popen(['RNAfold', '-p', '--noPS', '--constraint'],\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE, \n",
    "            stderr=subprocess.STDOUT)\n",
    "    stdout, stderr = MyOut.communicate(input=str.encode(sequence))\n",
    "    return stdout\n",
    "\n",
    "def get_energy_RNAfold(stdout_string):\n",
    "    '''\n",
    "    '''\n",
    "    temp = stdout_string.decode('utf-8') \n",
    "    energy_line = temp.split('\\n')[-5]\n",
    "    energy_val = energy_line[energy_line.index(' '):]\n",
    "    energy_val = energy_val.strip().strip('()').strip()\n",
    "    \n",
    "    mfe_line = temp.split('\\n')[-4]\n",
    "    mfe_val = mfe_line[energy_line.index(' '):]\n",
    "    mfe_val = mfe_val.strip().strip('[]').strip()\n",
    "    return float(energy_val), float(mfe_val)    \n",
    "\n",
    "def add_secondary_structure(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    for index in df.index:\n",
    "        us_seq = df.loc[index]['upstream_sequence'] \n",
    "        cds_seq = df.loc[index]['coding_sequence']\n",
    "        beg_cds_seq = cds_seq[:30]\n",
    "        if len(us_seq) == 30 and len(beg_cds_seq) == 30:\n",
    "            seq = us_seq + beg_cds_seq\n",
    "            rna_out = call_RNAfold(seq)\n",
    "            e1, e2 = get_energy_RNAfold(rna_out)\n",
    "            df.at[index, 'secondary_structure'] = e2\n",
    "            \n",
    "        if len(cds_seq) > 90:\n",
    "            int_cds_seq = cds_seq[30:90]\n",
    "            rna_out = call_RNAfold(int_cds_seq)\n",
    "            e1, e2 = get_energy_RNAfold(rna_out)\n",
    "            df.at[index, 'secondary_structure_internal'] = e2\n",
    "    return df\n",
    "\n",
    "def add_iCUB_and_GC(df):\n",
    "    '''\n",
    "    '''\n",
    "    for index in df.index:\n",
    "        cds_seq = df.loc[index]['coding_sequence']\n",
    "        if len(cds_seq) == 0:\n",
    "            continue\n",
    "        if len(cds_seq) != cds_seq.count('A') + cds_seq.count('T') + cds_seq.count('C') + cds_seq.count('G'):\n",
    "            continue\n",
    "        if len(cds_seq)%3 != 0:\n",
    "            continue\n",
    "        df.at[index, 'iCUB'] = iCUB.iCUB_Calculator(cds_seq).get_iCUB()\n",
    "        #\n",
    "        df.at[index, 'GC_cds'] = (cds_seq.count('G') + cds_seq.count('C')) / len(cds_seq)\n",
    "        #\n",
    "        us_seq = df.loc[index]['upstream_sequence']\n",
    "        if len(us_seq) == 30:\n",
    "            df.at[index, 'GC_upstream'] = (us_seq.count('G') + us_seq.count('C')) / len(us_seq)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook-wide parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = '\\t'\n",
    "upstream_len = 30\n",
    "\n",
    "with open('../Data/energy_files/energyRef_CCUCCU_ensemble_noneConstraint.json', 'r') as infile:\n",
    "       energy_dict = json.load(infile)\n",
    "        \n",
    "base_viral_genome_dir = '../Data/MVP_data/host_linked_genomes/'\n",
    "host_genome_dir = '../Data/MVP_data/host_genomes/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating `.tsv` files for host genomes\n",
    "\n",
    "**Adding relevant columns for ribosome binding sites, secondary structure, codon usage bias, and GC content. This whole process takes 5-10 minutes per genome. Could definitely be optimized but for now not a bottleneck, just anticipate a few hours for this cell to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ids = [36809,\\\n",
    "           717959,\\\n",
    "           305,\\\n",
    "           1590,\\\n",
    "           435591,\\\n",
    "           90371,\\\n",
    "           1314,\\\n",
    "           357276,\\\n",
    "           657318,\\\n",
    "           1639,\\\n",
    "           1428,\\\n",
    "           470,\\\n",
    "           573,\\\n",
    "           1280,\\\n",
    "           287,\\\n",
    "           562]\n",
    "\n",
    "for host_id in host_ids:\n",
    "    print(host_id)\n",
    "    ###Creates the dataframe based off a gff3 and fasta file\n",
    "    host_df, host_genome = gff3_parsing.compile_sequences([host_genome_dir + '{}.gff3'.format(host_id)],\\\n",
    "                                                        [host_genome_dir + '{}.fasta'.format(host_id)],\\\n",
    "                                                          upstream_len)\n",
    "    ###Adds the ribosome binding site energy column\n",
    "    host_df = add_RBS_energy(host_df, energy_dict, col_name='RBS_energy', gaps=(4,10))\n",
    "    host_df = add_RBS_energy(host_df, energy_dict, col_name='RBS_energy_upstream', gaps=(11,17))\n",
    "\n",
    "    ###Adds the secondary structure column\n",
    "    host_df = add_secondary_structure(host_df)\n",
    "    \n",
    "    ###Add codon usage bias column\n",
    "    host_df = add_iCUB_and_GC(host_df)\n",
    "    \n",
    "    ###Writes to a file\n",
    "    host_df.to_csv(host_genome_dir + '{}.tsv'.format(host_id), sep=sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat the 2 chromosome hosts slightly differently to ensure no errors occur\n",
    "\n",
    "(There is currently only one of these. And I don't love the solution because it's basically entirely copy/paste but here we are.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ids_2chrom = [28450]\n",
    "\n",
    "for host_id in host_ids_2chrom:\n",
    "    print(host_id)\n",
    "    gffs = [host_genome_dir + '{}.1.gff3'.format(host_id),\\\n",
    "            host_genome_dir + '{}.2.gff3'.format(host_id)]\n",
    "\n",
    "    fastas = [host_genome_dir + '{}.1.fasta'.format(host_id),\\\n",
    "              host_genome_dir + '{}.2.fasta'.format(host_id)]\n",
    "\n",
    "    host_df, host_genome = gff3_parsing.compile_sequences(gffs, fastas, upstream_len)\n",
    "    \n",
    "    ###Adds the ribosome binding site energy column\n",
    "    host_df = add_RBS_energy(host_df, energy_dict, col_name='RBS_energy', gaps=(4,10))\n",
    "    host_df = add_RBS_energy(host_df, energy_dict, col_name='RBS_energy_upstream', gaps=(11,17))\n",
    "\n",
    "    ###Adds the secondary structure column\n",
    "    host_df = add_secondary_structure(host_df)\n",
    "    \n",
    "    ###Add codon usage bias column\n",
    "    host_df = add_iCUB_and_GC(host_df)\n",
    "    \n",
    "    ###Writes to a file\n",
    "    host_df.to_csv(host_genome_dir + '{}.tsv'.format(host_id), sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating `.tsv` files for viral genomes\n",
    "**There are a lot more of these viral genomes but they're super small so run-time for this cell should also be in the few hour range at most. And it only needs to happen once so this isn't a bottleneck and I'm not concerning myself with speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Concatenate the two existing host lists\n",
    "host_ids = host_ids + host_ids_2chrom\n",
    "for host_id in host_ids:\n",
    "    print('#####', host_id)\n",
    "    for gff_file in glob.glob(base_viral_genome_dir+'{}_rep_viruses/*.gff3'.format(host_id)):\n",
    "        print(gff_file)\n",
    "        fasta_file = gff_file.replace('.gff3', '.fasta')\n",
    "        tsv_file = gff_file.replace('.gff3', '.tsv')\n",
    "        \n",
    "        viral_df, viral_genome = gff3_parsing.compile_sequences([gff_file], [fasta_file], upstream_len)\n",
    "        \n",
    "        ###Adds the ribosome binding site energy column\n",
    "        viral_df = add_RBS_energy(viral_df, energy_dict, col_name='RBS_energy', gaps=(4,10))\n",
    "        viral_df = add_RBS_energy(viral_df, energy_dict, col_name='RBS_energy_upstream', gaps=(11,17))\n",
    "\n",
    "        ###Adds the secondary structure column\n",
    "        viral_df = add_secondary_structure(viral_df)\n",
    "\n",
    "        ###Add codon usage bias column\n",
    "        viral_df = add_iCUB_and_GC(viral_df)\n",
    "\n",
    "        ###Writes to a file\n",
    "        viral_df.to_csv(tsv_file, sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make \"clean\" `.tsv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_cleaning(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[df['upstream_sequence'].isnull()==False]\n",
    "    df = df[df['coding_sequence'].isnull()==False]\n",
    "    df = df[df['iCUB'].isnull()==False]\n",
    "    df = df[df['GC_cds'].isnull()==False]\n",
    "    df = df[df['GC_upstream'].isnull()==False]\n",
    "    df = df[df['RBS_energy'].isnull()==False]\n",
    "    df = df[df['RBS_energy_upstream'].isnull()==False]\n",
    "    return df\n",
    "\n",
    "def clean_host_tsv(df):\n",
    "    \"\"\"\n",
    "    WRITE A BRIEF PURPOSE/SUMMARY\n",
    "    \n",
    "    Development notes: I could also think about testing for stop codons within coding sequences\n",
    "    and filtering accordingly. Also a way to test for possible non-standard genetic code usage\n",
    "    \n",
    "    Input/s:\n",
    "        df - a pandas dataframe with numeric indices, outputted from Compile_data.ipynb and read\n",
    "                back in\n",
    "        \n",
    "    Output/s:\n",
    "        df - a clean version of the dataframe with one new column (iCUB) and (potentially)\n",
    "                several rows removed\n",
    "    \"\"\"\n",
    "    ###Run the main cleaning/additions\n",
    "    df = common_cleaning(df)\n",
    "    \n",
    "    ###Filter out possible prophage genes by removing anything involving the word phage\n",
    "    ###Numerous possibilities/ways to do this and not all genomes might have any decent\n",
    "    ###descriptions in the qualifiers.\n",
    "    filter_word = 'phage'\n",
    "    df = df[(df['qualifiers'].str.contains(filter_word)==False)]\n",
    "    \n",
    "    ###Now ensure that each locus tag is only used once and when in doubt remove them both\n",
    "    df['locus_tag'] = df['qualifiers'].str.split('locus_tag=', n=1, expand=True)[1]\\\n",
    "                            .str.split(';', n=1, expand=True)[0]\n",
    "    df = df.drop_duplicates(subset = ['locus_tag'], keep = False)\n",
    "    return df\n",
    "\n",
    "def clean_virus_tsv(df):\n",
    "    \"\"\"\n",
    "    This is the same basic structure as the \"clean_host_tsv\" function. \n",
    "    \n",
    "    Input/s:\n",
    "        df - a pandas dataframe with numeric indices, outputted from Compile_data.ipynb and read\n",
    "                back in\n",
    "        \n",
    "    Output/s:\n",
    "        df - a clean version of the dataframe with one new column (iCUB) and (potentially)\n",
    "                several rows removed\n",
    "                \n",
    "    \"\"\"  \n",
    "    ###Run the main cleaning/additions\n",
    "    df = common_cleaning(df)\n",
    "\n",
    "    ###Now ensure that each viral_id tag is only used once (and when in doubt remove them BOTH)\n",
    "    df['viral_id'] = df['qualifiers'].str.split('ID=', n=1, expand=True)[1]\\\n",
    "                            .str.split(';', n=1, expand=True)[0]\n",
    "    \n",
    "    df = df.drop_duplicates(subset = [\"viral_id\"], keep = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side analysis just to make sure that all these genomes use the standard translation table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/MVP_data/host_genomes/28450.tsv\n",
      "5727 [('11', 5727)]\n",
      "../Data/MVP_data/host_genomes/1590.tsv\n",
      "3013 [('11', 3013)]\n",
      "../Data/MVP_data/host_genomes/562.tsv\n",
      "4379 [('11', 4379)]\n",
      "../Data/MVP_data/host_genomes/357276.tsv\n",
      "4343 [('11', 4343)]\n",
      "../Data/MVP_data/host_genomes/657318.tsv\n",
      "3294 [('11', 3294)]\n",
      "../Data/MVP_data/host_genomes/573.tsv\n",
      "5316 [('11', 5316)]\n",
      "../Data/MVP_data/host_genomes/1280.tsv\n",
      "2767 [('11', 2767)]\n",
      "../Data/MVP_data/host_genomes/305.tsv\n",
      "3466 [('11', 3466)]\n",
      "../Data/MVP_data/host_genomes/435591.tsv\n",
      "3979 [('11', 3979)]\n",
      "../Data/MVP_data/host_genomes/470.tsv\n",
      "4327 [('11', 4327)]\n",
      "../Data/MVP_data/host_genomes/287.tsv\n",
      "5573 [('11', 5573)]\n",
      "../Data/MVP_data/host_genomes/1314.tsv\n",
      "1693 [('11', 1690)]\n",
      "../Data/MVP_data/host_genomes/36809.tsv\n",
      "4920 [('11', 4920)]\n",
      "../Data/MVP_data/host_genomes/717959.tsv\n",
      "3110 [('11', 3110)]\n",
      "../Data/MVP_data/host_genomes/90371.tsv\n",
      "4447 [('11', 4447)]\n",
      "../Data/MVP_data/host_genomes/1639.tsv\n",
      "2867 [('11', 2867)]\n",
      "../Data/MVP_data/host_genomes/1428.tsv\n",
      "5117 [('11', 5117)]\n"
     ]
    }
   ],
   "source": [
    "for host_tsv_file in glob.glob(host_genome_dir + '*.tsv')[:]:\n",
    "    if '.clean.' in host_tsv_file:\n",
    "        continue\n",
    "    print(host_tsv_file)\n",
    "    df = pd.read_csv(host_tsv_file, sep = '\\t', index_col = 0)\n",
    "    df['transl_table'] = df['qualifiers'].str.split('transl_table=', n=1, expand=True)[1]\\\n",
    "                        .str.split(';', n=1, expand=True)[0]\n",
    "    print(df.shape[0], list(df['transl_table'].value_counts().items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First host data tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/MVP_data/host_genomes/28450.tsv\n",
      "0.9776497293521914\n",
      "../Data/MVP_data/host_genomes/1590.tsv\n",
      "0.9495519415864587\n",
      "../Data/MVP_data/host_genomes/562.tsv\n",
      "0.9271523178807947\n",
      "../Data/MVP_data/host_genomes/357276.tsv\n",
      "0.9689154962007829\n",
      "../Data/MVP_data/host_genomes/657318.tsv\n",
      "0.9875531268973892\n",
      "../Data/MVP_data/host_genomes/573.tsv\n",
      "0.9834462001504891\n",
      "../Data/MVP_data/host_genomes/1280.tsv\n",
      "0.9555475243946513\n",
      "../Data/MVP_data/host_genomes/305.tsv\n",
      "0.9676860934795153\n",
      "../Data/MVP_data/host_genomes/435591.tsv\n",
      "0.9856747926614727\n",
      "../Data/MVP_data/host_genomes/470.tsv\n",
      "0.9315923272475156\n",
      "../Data/MVP_data/host_genomes/287.tsv\n",
      "0.9971290148932352\n",
      "../Data/MVP_data/host_genomes/1314.tsv\n",
      "0.941523922031896\n",
      "../Data/MVP_data/host_genomes/36809.tsv\n",
      "0.9902439024390244\n",
      "../Data/MVP_data/host_genomes/717959.tsv\n",
      "0.9305466237942123\n",
      "../Data/MVP_data/host_genomes/90371.tsv\n",
      "0.947829997751293\n",
      "../Data/MVP_data/host_genomes/1639.tsv\n",
      "0.9895361004534357\n",
      "../Data/MVP_data/host_genomes/1428.tsv\n",
      "0.9976548759038499\n"
     ]
    }
   ],
   "source": [
    "for host_tsv_file in glob.glob(host_genome_dir + '*.tsv'):\n",
    "    if '.clean.' in host_tsv_file:\n",
    "        continue\n",
    "    print(host_tsv_file)\n",
    "    ###\n",
    "    df = pd.read_csv(host_tsv_file, sep='\\t', index_col=0)\n",
    "    initial_shape = df.shape\n",
    "    df = clean_host_tsv(df)\n",
    "    final_shape = df.shape\n",
    "    ###\n",
    "    gene_ratio = final_shape[0]/initial_shape[0]\n",
    "    print(gene_ratio)\n",
    "    if gene_ratio <= 0.8: #This basically shouldn't happen\n",
    "        break\n",
    "    ###\n",
    "    clean_tsv_loc = host_tsv_file.replace('.tsv', '.clean.tsv')\n",
    "    df.to_csv(clean_tsv_loc, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, phage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ../Data/MVP_data/host_linked_genomes/1314_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/36809_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/28450_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/562_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/470_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/435591_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/305_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/717959_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/1639_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/657318_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/1280_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/1428_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/573_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/90371_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/1590_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/357276_rep_viruses/\n",
      "### ../Data/MVP_data/host_linked_genomes/287_rep_viruses/\n"
     ]
    }
   ],
   "source": [
    "for virus_folder in glob.glob(base_viral_genome_dir + '*_rep_viruses/'):\n",
    "    print('###', virus_folder)\n",
    "    for virus_tsv_file in glob.glob(virus_folder + '*.tsv'):\n",
    "        if '.clean.' in virus_tsv_file:\n",
    "            continue\n",
    "        print(virus_tsv_file)\n",
    "        ###\n",
    "        df = pd.read_csv(virus_tsv_file, sep='\\t', index_col=0)\n",
    "        initial_shape = df.shape\n",
    "        df = clean_virus_tsv(df)\n",
    "        final_shape = df.shape\n",
    "        ###\n",
    "        gene_ratio = final_shape[0]/initial_shape[0]\n",
    "        if gene_ratio <= 0.8:\n",
    "            print('Strange case', gene_ratio)\n",
    "            break\n",
    "        ###\n",
    "        clean_tsv_loc = virus_tsv_file.replace('.tsv', '.clean.tsv')\n",
    "        df.to_csv(clean_tsv_loc, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
